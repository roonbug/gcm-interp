- one-giant-eval.py -- gives you a single giant eval file with all pre and post-intervention responses and associated metadata
- gen-judge-qs-dataframe.py -- gives you a dataframe of all the judge prompts used in vLLM judge evaluations
- gen-relevancy-qs-dataframe.py -- gives you a dataframe of all the relevance prompts used in vLLM judge evaluations
- breakup.py -- breaks up judge, relevance, fluency evaluations into smaller chunks for easier processing
- evaluator.py -- evaluates the results from vLLM judge evaluations (relevance, fluency, judge)